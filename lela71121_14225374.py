# -*- coding: utf-8 -*-
"""LELA71121 14225374

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mgHVEmFE4NMTnd5wINL-lxLt3Melfmhs
"""

#Import all modules/dependencies
import csv
import re
import numpy as np
import sys
import os
import copy
import math
import matplotlib.pyplot as plt
from collections import Counter
from scipy.stats import mannwhitneyu
from sklearn.metrics import roc_auc_score

#Set fixed random seed for reproducibility
np.random.seed(300)

"""Download and Preprocess Text Data from Pitt Cookie Theft Corpus"""

#Runtime note: additional runtime expected
!gdown 1q0BwIS3gbzDAQZBjcYCG0ia_I6zeL0qN

!unzip Pitt.zip

#FUNCTION N.1 -> Walk through every subdirectory, find .cha files,
#clean them, generate cleaned .rem versions, and return their text
def recurse_dirs(dir):

    outtext=[]
    outlist = []
    corpora = os.listdir(dir)
    for corpus in corpora:
        path = dir + corpus
        dirbin = []
        print(corpus)
        for d_path, d_names, f_names in os.walk(path):

            if any(fname.endswith('.cha') for fname in os.listdir(d_path)):
                subdir = d_path + "/"
                remove_embedded_returns(subdir)
                for f in os.listdir(subdir):
                    if f.endswith('.rem'):

                      outtext.append(get_file_text(subdir + f,f))
    return outtext

#FUNCTION N.2 -> Extract only participant speech and apply regex cleaning functions for removing interactional markers and metadata

def get_file_text(file,filename):

    thistext = []
    previousline="START"
    with open(file, 'r') as infile:
        lines = infile.readlines()
        i = 0
        for line in lines:
             i=i+1
             if not re.match(".*xxx.*",line) and not re.match(".*www.*",line):

               if re.match("\*(PAR)\:",line.rstrip('\n')):

                    speaker = re.search("\*(PAR)\:",line)[0]
                    line = deal_with_variant_forms(line)
                    line = deal_with_marked_errors_etc(line)
                    line = re.sub(r"\+/\S*", "", line) #interruptions
                    line = re.sub("\+\"\/? ","",line) #quotations
                    line = re.sub("\+\/+\? ","",line) #interruption of a question
                    line = re.sub(r"\+\/+","",line) #interruptions
                    line = re.sub(r"\+\"\/","",line) #quotations
                    line = re.sub(r"\+\"","",line) #quotations
                    line = deal_with_special_characters(line)
                    line = re.sub(r"\++ ","",line) #completance of an utterance
                    line = re.sub(r"\@[^ l]+","",line) #ID markers
                    line = re.sub(r"[\x00-\x1F\x7F]", "", line) #ID markers
                    line = re.sub(r"0[^ ]*","",line) #Removes 0
                    line = re.sub(r";","",line) # Removes ;
                    line = re.sub("([^ ]+)\@[a-z]","\\1",line) #email addresses
                    line = re.sub("([^ ]+) [^ ]+$","\\1",line)
                    line = re.sub("&\*[^\s]+", "", line)
                    if i <= len(lines):
                      response  = line.split(':',1)[1]
                      response = re.sub("\:","",response)
                      response_as_list=response.split()

                      if len(response_as_list) > 0:
                          outp = " ".join(response_as_list)
                          thistext.append(outp)
    return(thistext)

#FUNCTION N.3 -> Fix embedded line breaks inside CHAT speaker turns
def remove_embedded_returns(my_dir):
    files = sorted(f for f in os.listdir(my_dir)if not f.startswith("."))

    for file in files:
        if (('.cha' in file
             or '.cex' in file)
            and '.rem' not in file
                and '._' not in file):
            with open(my_dir + file, 'r') as infile:
                inlist = infile.readlines()
                for i in range(len(inlist)):
                    inlist[i] = inlist[i].split()
                    if inlist[i] == []:
                        inlist[i] = ['binthis']
                while ['binthis'] in inlist:
                    inlist.remove(['binthis'])
                for j in range(5):
                    for i in range(len(inlist)):
                        if (len(inlist[i]) > 0
                            and inlist[i][0][0] in ['%', '*', '@', '%']
                            and i < len(inlist) - 2
                            and inlist[i+1][0][0] not in ['%', '*', '@', '%']
                                and inlist[i+1] != ['binthis']):
                            inlist[i] = copy.deepcopy(
                                inlist[i]) + copy.deepcopy(inlist[i+1])
                            inlist[i+1] = ['binthis']
                        if inlist[i] == []:
                            inlist[i] = ['binthis']
                    while ['binthis'] in inlist:
                        inlist.remove(['binthis'])

            with open(my_dir + file + '.rem', 'w') as outfile:
                for line in inlist:
                    outfile.write(' '.join(line) + '\n')

#FUNCTION N.4 -> Handle general variant forms and normalise text
def deal_with_variant_forms(textline):
    textline = textline.split(" ")
    newtextline = []
    lastitem = ''
    lastbutoneitem = ''
    #lastbuttwoitem = ''
    # print textline
    for item in textline:
        item = item.replace('(', '')
        item = item.replace(')', '')

        if item == '[:':
          break
        else:
          newtextline.append(item.lower())
    return " ".join(newtextline)

#FUNCTION N.5 -> Remove CHAT markup that indicates errors, retracing, non-speech, or special annotations
def deal_with_marked_errors_etc(textline):
    textline = textline.replace('\]\[', '] [')
    textline = re.sub('([^ ]),','\\1 ,', textline)
    textline = re.sub(',([^ ])',', \\1', textline)
    textline = re.sub('\<','', textline)
    textline = re.sub('\>','', textline)
    textline = re.sub('\[[^\[\]]*\] ?', '', textline)
    textline = re.sub('\(\.\) ?', '', textline)

    textline = textline.replace('0is ', '')
    return textline

#FUNCTION N.6 -> Normalise punctuation
def deal_with_special_characters(textline):
    # outline = re.sub("\, ","",textline)
    outline = re.sub("„ ",", ",textline)
    return outline

all_participant_speech = recurse_dirs("Pitt/")

cleaned = recurse_dirs("Pitt/Dementia/cookie")

def extract_cleaned_text(directory):
    all_cleaned_texts = []

#Go through the specified directory and returns a path (string) and list of all filenames
    for dirpath, dirs, files in os.walk(directory):
        for f in files:

#Check whether its a clean .rem file
            if f.endswith(".cha.rem"):
#Builds the full path to the file by joining the directory path and the filename
                filepath = os.path.join(dirpath, f)
#Reads the file and applies all cleaning processes from code above
                cleaned = get_file_text(filepath, f)

                if cleaned:
                    all_cleaned_texts.append(cleaned)
    return all_cleaned_texts

#Texts still seperated into one item per line
cleaned_control_texts = extract_cleaned_text("Pitt/Control/cookie")
cleaned_dementia_texts = extract_cleaned_text("Pitt/Dementia/cookie")

#Create one string item per text
dem_texts = [" ".join(sublist) for sublist in cleaned_dementia_texts]
con_texts = [" ".join(sublist) for sublist in cleaned_control_texts]

#Extract a vocab from texts
dem_tokens = [txt.split() for txt in dem_texts]
con_tokens = [txt.split() for txt in con_texts]

#Create x input matrix for one hot encoding
x = con_tokens + dem_tokens
#Create binary coded y array for classification model
y_control=[0]*len(con_tokens)
y_dementia = [1]*len(dem_tokens)
y = y_control+y_dementia

"""Build One-Hot Encoded Training, Dev and Test Matrices"""

#Build a vocabualry using the most frequent 1500 words
word_counts = Counter([word for doc in x for word in doc])
full_vocab = list(word_counts.keys())
sorts = sorted(word_counts.items(), key=lambda item: item[1], reverse=True)
vocab = [word for word, count in sorts[:1500]]
print(f"Total vocab length: {len(full_vocab)}")
print(f"Selected vocab length: {len(vocab)}")

#Build one-hot encoded input matrix from vocab

M = np.zeros((len(x), len(vocab)))

for i, txt in enumerate(x):
    text_tokens = txt

    for j, t in enumerate(vocab):
        if t in text_tokens:
          M[i,j] = 1

#Generate random indicies for splitting data
train_ints = np.random.choice(len(x), int(len(x)*0.7), replace=False)
remaining_ints = list(set(range(len(x))) - set(train_ints))
test_ints = np.random.choice(remaining_ints, int(len(remaining_ints)*0.5), replace=False)
dev_ints = list(set(remaining_ints) - set(test_ints))

#Generate one-hot encoded input matrices for training, development and test using random indicies
M_train = np.array([M[i] for i in train_ints])
M_test = np.array([M[i] for i in test_ints])
M_dev = np.array([M[i] for i in dev_ints])

y_train = [y[i] for i in train_ints]
y_test = [y[i] for i in test_ints]
y_dev = [y[i] for i in dev_ints]

#Check class balence for each data split
print(f"Training: {np.mean(y_train):.3f}")
print(f"Dev: {np.mean(y_dev):.3f}")
print(f"Test: {np.mean(y_test):.3f}")

"""Train and Evaluate Logistic Regression Classifier"""

#Set model hyperparameters and dimensions
num_features=len(vocab)
weights = np.random.rand(num_features)
bias=np.random.rand(1)
n_iters = 3000
lr=0.05
num_samples=len(y_train)

#Initilaise loss function
logistic_loss=[]

#Forwards pass through the model
for i in range(n_iters):
  z= np.dot(M_train, weights) + bias
  q = 1/(1+np.exp(-z))

#Calculate loss per epoch and append to loss function (using eps to avoid errors from log(0))
  eps=0.00001
  loss = -np.sum((y_train*np.log2(q+eps)+(np.ones(len(y_train))-y_train)*np.log2(np.ones(len(y_train))-q+eps)))
  logistic_loss.append(loss)

#Calculate partial devs and update weights/bias
  dw = (1/num_samples) * (np.dot(q-y_train, M_train))
  db = (1/num_samples) * np.sum(q-y_train)
  weights -= dw*lr
  bias -= db*lr

#Inspect loss over epochs
plt.plot(range(1,n_iters),logistic_loss[1:])
plt.xlabel("number of epochs")
plt.ylabel("loss")

"""Evaluation on the Dev Set (for hyperparameter tuning)"""

#Calculate predicted values for the dev set
dev_z = np.dot(M_dev, weights) + bias
dev_q = 1/(1+np.exp(-dev_z))
y_dev_pred = [int(q1 > 0.5) for q1 in dev_q]

true_positives = sum((yp == 1 and y_dev[s] == 1) for s,yp in enumerate(y_dev_pred))
true_negatives = sum((yp == 0 and y_dev[s] == 0) for s,yp in enumerate(y_dev_pred))
false_positives = sum((yp == 1 and y_dev[s] == 0) for s,yp in enumerate(y_dev_pred))
false_negatives = sum((yp == 0 and y_dev[s]== 1) for s,yp in enumerate(y_dev_pred))

accuracy = (true_positives+true_negatives)/len(y_dev)
precision = true_positives/(true_positives+false_positives)
recall = true_positives/(true_positives + false_negatives)
dev_auc = roc_auc_score(y_dev, dev_q)

print(f"Predictions class balence: {np.mean(y_dev_pred):.3f}")
print(f"Accuracy : {accuracy:.3f}")
print(f"Precision : {precision:.3f}")
print(f"Recall : {recall:.3f}")
print(f"F1: {2 * (precision * recall) / (precision + recall):.3f}")
print(f"AUC: {dev_auc:.3f}")

"""Evaluation on the Training Set (to examine overfitting)"""

#Calculate predicted values for the training set
train_z = np.dot(M_train, weights) + bias
train_q = 1/(1+np.exp(-train_z))
y_train_pred = [int(q1 > 0.5) for q1 in train_q]

true_positives = sum((yp == 1 and y_train[s] == 1) for s, yp in enumerate(y_train_pred))
true_negatives = sum((yp == 0 and y_train[s] == 0) for s, yp in enumerate(y_train_pred))
false_positives = sum((yp == 1 and y_train[s] == 0) for s, yp in enumerate(y_train_pred))
false_negatives = sum((yp == 0 and y_train[s] == 1) for s, yp in enumerate(y_train_pred))

accuracy = (true_positives+true_negatives)/len(y_train)
precision = true_positives/(true_positives+false_positives)
recall = true_positives/(true_positives + false_negatives)
train_auc = roc_auc_score(y_train, train_q)

print(f"Predictions class balence: {np.mean(y_train_pred):.3f}")
print(f"Accuracy : {accuracy:.3f}")
print(f"Precision : {precision:.3f}")
print(f"Recall : {recall:.3f}")
print(f"F1: {2 * (precision * recall) / (precision + recall):.3f}")
print(f"AUC: {train_auc:.3f}")

"""Evaluation on the Test Set (for reporting results)"""

#Calculate predicted values for the test set
test_z = np.dot(M_test, weights) + bias
test_q = 1 / (1 + np.exp(-test_z))
y_test_pred = [int(q1 > 0.5) for q1 in test_q]

true_positives  = sum((yp == 1 and y_test[s] == 1) for s, yp in enumerate(y_test_pred))
true_negatives  = sum((yp == 0 and y_test[s] == 0) for s, yp in enumerate(y_test_pred))
false_positives = sum((yp == 1 and y_test[s] == 0) for s, yp in enumerate(y_test_pred))
false_negatives = sum((yp == 0 and y_test[s] == 1) for s, yp in enumerate(y_test_pred))

accuracy = (true_positives+true_negatives)/len(y_test)
precision = true_positives/(true_positives+false_positives)
recall = true_positives/(true_positives + false_negatives)
test_auc = roc_auc_score(y_test, test_q)

print(f"Predictions class balence: {np.mean(y_test_pred):.3f}")
print(f"Accuracy : {accuracy:.3f}")
print(f"Precision : {precision:.3f}")
print(f"Recall : {recall:.3f}")
print(f"F1: {2 * (precision * recall) / (precision + recall):.3f}")
print(f"AUC: {test_auc:.3f}")

#Examine 'bottom' weights (pushing in negative direction towards 0 -> control samples)
[vocab[x] for x in np.argsort(weights)[0:25]]

#Examine 'top' weights (pushing in positive direction towards 1 -> AD samples)
[vocab[x] for x in np.argsort(weights)[::-1][0:25]]

"""Extract and analyse Lexical-grammatical density features (using spacy POS tags)"""

#Runtime note: additional runtime expected
#Download spaCy
!python -m spacy download en_core_web_trf

#Load spaCy
import en_core_web_trf
nlp_en = en_core_web_trf.load()

#Runtime note: additional runtime expected
#Run spacy over texts and store parsed documents
spacy_dem_docs =[]
for txt in dem_texts:
  doc = nlp_en(txt)
  spacy_dem_docs.append(doc)

spacy_con_docs = []
for txt in con_texts:
  doc = nlp_en(txt)
  spacy_con_docs.append(doc)

#Define function for extracting the rate of predicate use per doc
def pred_rate(spacy_docs):
    pred_rates = []
    for doc in spacy_docs:
        n_pred = sum(tok.pos_ in {"VERB", "AUX"} for tok in doc)
        n_tokens = len(re.findall(r"[A-Za-z']+", doc.text))
        pred_rates.append(n_pred / n_tokens)
    return pred_rates

#Extract and print predicate rate means per group
dem_pred_rates = pred_rate(spacy_dem_docs)
con_pred_rates = pred_rate(spacy_con_docs)

print("Dementia Texts:")
print(f"Mean predicate rate: {np.mean(dem_pred_rates):.3f}")
print("Control Texts:")
print(f"Mean predicate rate: {np.mean(con_pred_rates):.3f}")

#Define function for extracting the rate of pronoun use per doc
def pron_rate(spacy_docs):
    pron_rates = []
    for doc in spacy_docs:
        n_pron = sum(tok.pos_ == "PRON" for tok in doc)
        n_tokens = len(re.findall(r"[A-Za-z']+", doc.text))
        pron_rates.append(n_pron / n_tokens)
    return pron_rates

#Extract and print pronoun rate means per group
dem_pron_rates = pron_rate(spacy_dem_docs)
con_pron_rates = pron_rate(spacy_con_docs)

print("Dementia Texts:")
print(f"Mean pronoun rate: {np.mean(dem_pron_rates):.3f}")
print("Control Texts:")
print(f"Mean pronoun rate: {np.mean(con_pron_rates):.3f}")

#Define functions for extracting content and function word rates
def content_rate(spacy_docs):
    content_rates = []
    for doc in spacy_docs:
        n_content = sum(tok.pos_ in {"VERB", "NOUN", "ADJ", "ADV", "PROPN"} for tok in doc)
        n_tokens = len(re.findall(r"[A-Za-z']+", doc.text))
        content_rates.append(n_content / n_tokens)
    return content_rates


def function_rate(spacy_docs):
    function_rates = []
    for doc in spacy_docs:
        n_function = sum(tok.pos_ in {"PRON", "DET", "ADP", "CCONJ", "SCONJ", "AUX", "PART"} for tok in doc)
        n_tokens = len(re.findall(r"[A-Za-z']+", doc.text))
        function_rates.append(n_function / n_tokens)
    return function_rates

#Extract and print content and function words rate means per group
dem_content_rates = content_rate(spacy_dem_docs)
con_content_rates = content_rate(spacy_con_docs)

dem_function_rates = function_rate(spacy_dem_docs)
con_function_rates = function_rate(spacy_con_docs)


print("Dementia Texts:")
print(f"Mean content words rate: {np.mean(dem_content_rates):.3f}")
print(f"Mean function words rate: {np.mean(dem_function_rates):.3f}")
print("Control Texts:")
print(f"Mean content words rate: {np.mean(con_content_rates):.3f}")
print(f"Mean function words rate: {np.mean(con_function_rates):.3f}")

"""Calculate Lexical Diversity Measures"""

#Create 'cleaned' docs contaning only lower case words (remove CHAT symbols)
dem_clean_docs = []
for doc in dem_tokens:
    clean_doc = []
    for word in doc:
        w = re.sub(r"[^A-Za-z']", "", word.lower())
        if w:
            clean_doc.append(w)
    dem_clean_docs.append(clean_doc)

con_clean_docs = []
for doc in con_tokens:
    clean_doc = []
    for word in doc:
        w = re.sub(r"[^A-Za-z']", "", word.lower())
        if w:
            clean_doc.append(w)
    con_clean_docs.append(clean_doc)

#Define a function for calculating brunets index measure using cleaned docs
def brunets_index(doc, a=0.165):
    N = len(doc)
    V = len(set(doc))
    return N ** (V ** (-a))

#Extract and print group means for BI per doc
dem_BI = [brunets_index(doc) for doc in dem_clean_docs]
con_BI = [brunets_index(doc) for doc in con_clean_docs]

print(f"Dementia Mean: {np.mean(dem_BI):.3f}")
print(f"Control Mean: {np.mean(con_BI):.3f}")

#Define a function for calculating honores statistic measure using cleaned docs
def honores_statistic(doc):
    N = len(doc)

    counts = Counter(doc)
    V = len(counts)

    V1 = sum(1 for c in counts.values() if c == 1)
    denom = 1 - (V1 / V)

    return 100 * math.log(N) / denom

#Extract and print group means for H per doc
dem_H = [honores_statistic(doc) for doc in dem_clean_docs]
con_H = [honores_statistic(doc) for doc in con_clean_docs]
print(f"Dementia Mean: {np.mean(dem_H):.3f}")
print(f"Control Mean: {np.mean(con_H):.3f}")

"""Extract and Analyse Lexical Retrival and Disfluency Features using CHAT Transcription Symbols"""

#Define regex patterns for fluency features according to CHAT transcription
chat_patterns = {"Fillers": r"&-",
            "Phonological Fragments": r"&\+",
            "Missing words": r"&=",
            "Long pauses": r"(?<!\+)\.\.\.",
            "Trailing off": r"\+\.\.\."}

#Define function to extract rate of regex patterns from spacy docs (doc.text still contains CHAT symbols)
def marker_rates(spacy_docs):
    rates = {name: [] for name in chat_patterns}

    for doc in spacy_docs:
        n_tokens = len(re.findall(r"[A-Za-z']+", doc.text))


        for name, pat in chat_patterns.items():
            count = len(re.findall(pat, doc.text))
            rates[name].append(count / n_tokens)

    return rates

#Store group rates for each marker type in dictionaries
dem_rates = marker_rates(spacy_dem_docs)
con_rates = marker_rates(spacy_con_docs)

#Extract and print lexical retrival and disfluency feature rates per group
for k in dem_rates:
    print(f"{k} -> "
          f"Dementia mean: {np.mean(dem_rates[k]):.4f} "
          f"Control mean: {np.mean(con_rates[k]):.4f}")

#Create seperate lists for each marker (for future AUC stat analysis)
dem_fills = dem_rates["Fillers"]
con_fills = con_rates["Fillers"]
dem_phon_frags = dem_rates["Phonological Fragments"]
con_phon_frags = con_rates["Phonological Fragments"]
dem_missw = dem_rates["Missing words"]
con_missw = con_rates["Missing words"]
dem_pauses = dem_rates["Long pauses"]
con_pauses = con_rates["Long pauses"]
dem_trail = dem_rates["Trailing off"]
con_trail = con_rates["Trailing off"]

"""Examining Lengths of Text in Dementia verus Control Settings"""

#Calculate mean length for dementia and control texts
dem_text_lengths = []
for doc in spacy_dem_docs:
  length = (len(re.findall(r"[A-Za-z']+", doc.text)))
  dem_text_lengths.append(length)

con_text_lengths = []
for doc in spacy_con_docs:
  length = (len(re.findall(r"[A-Za-z']+", doc.text)))
  con_text_lengths.append(length)



print(f"Dementia Mean: {np.mean(dem_text_lengths):.3f}")
print(f"Control Mean: {np.mean(con_text_lengths):.3f}")

"""Dementia versus Control Group Differences in Features

Mann–Whitney U tests were used, as rate-based linguistic features are not expected to follow Gaussian distributions. However, p-values from this test are ignored due to repeated measures in the data (from the same speaker). Instead the U statistic is used to calculate AUC for reporting differences between groups.

Lexical-grammatical density features
"""

#Define number of texts per group (for reuse)
n1 = len(dem_texts)
n2 = len(con_texts)

#Predicate Rate
stat, p = mannwhitneyu(dem_pred_rates, con_pred_rates)
print(f"AUC stat: {stat/(n1*n2):.3f}")

#Pronoun Rate
stat, p = mannwhitneyu(dem_pron_rates, con_pron_rates)
print(f"AUC stat: {stat/(n1*n2):.3f}")

#Content Words Rate
stat, p = mannwhitneyu(dem_content_rates, con_content_rates)
print(f"AUC stat: {stat/(n1*n2):.3f}")

#Function Words Rate
stat, p = mannwhitneyu(dem_function_rates, con_function_rates)
print(f"AUC stat: {stat/(n1*n2):.3f}")

"""Lexical Diversity Features"""

#Brunets Index Measure
stat, p = mannwhitneyu(dem_BI, con_BI)
print(f"AUC stat: {stat/(n1*n2):.3f}")

#Honores Statistic Measure
stat, p = mannwhitneyu(dem_H, con_H)
print(f"AUC stat: {stat/(n1*n2):.3f}")

"""Lexical Retrival and Disfluency Features"""

#Rate of Fillers
stat, p = mannwhitneyu(dem_fills, con_fills)
print(f"AUC stat: {stat/(n1*n2):.3f}")

#Rate of Phonological Fragments
stat, p = mannwhitneyu(dem_phon_frags, con_phon_frags)
print(f"AUC stat: {stat/(n1*n2):.3f}")

#Rate of Missing Words
stat, p = mannwhitneyu(dem_missw, con_missw)
print(f"AUC stat: {stat/(n1*n2):.3f}")

#Rate of Long Pauses
stat, p = mannwhitneyu(dem_pauses, con_pauses)
print(f"AUC stat: {stat/(n1*n2):.3f}")

#Rate of Trailing Off
stat, p = mannwhitneyu(dem_trail, con_trail)
print(f"AUC stat: {stat/(n1*n2):.3f}")

"""Text Lengths"""

#Text Lengths
stat, p = mannwhitneyu(dem_text_lengths, con_text_lengths)
print(f"AUC stat: {stat/(n1*n2):.3f}")